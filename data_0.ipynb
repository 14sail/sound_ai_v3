{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preprocessing \n",
    "* 先前以確認且處理過Rick的資料集（英文help與alarm）\n",
    "* 環境音從yt找了兩組居家的聲音 隨機採剪而成\n",
    "* 這隻程式碼將進行資料的擴增（在val不改變的前提之下）\n",
    "\n",
    "* This code is mainly based on Rick's fold 1 clean and check his data is okay.\n",
    "* I found some problems in the v1. For example :the raw data is not the real raw, and some audio has a different preprocessing.\n",
    "\n",
    "* We have a new target, so we need to make a new corrected data, and also need to make the automatic flowork data building and analysis. (if have time the EDA is also important)\n",
    "\n",
    "**<font color=#808080> == original notes == </font>**\n",
    "- 國83 台45 日104 先只試國語跟之前的 再加上日語的\n",
    "- 第一份npz 將嘗試用於 single fold 1s\n",
    "- save name : help3_single_fold_sp_in1s.npz (切分訓練測試驗證)\n",
    "\n",
    "**<font color=#808080> == New Target == </font>**\n",
    "- try to build an automatic flowork pipeline for easy to compute in the feature engineering.\n",
    "(this pipeline not only the data preprocessing but also the feature engineering, model training, model pruning, conversion...)\n",
    "\n",
    "- new detect target is main of two groups: \n",
    "    1.alarm (fire alarm, gas, smoke) and \n",
    "    2.help(eng, jap, cha, hak)\n",
    "- delete moaning\n",
    "- hak has less data but don't matter, we need to focus on the train set all can detect correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the beginning, I picked up some data from the online, Youtube, opendata... and make sure that will be able to train in this project.\n",
    "- the \"help\" data is clipped by hand, that are not all about 1s.\n",
    "- help data we need to clip \"start\" until 1s.\n",
    "- the \"alarm\" data and other(to augment) I think we can randomly clip 1s. but we also need listening \n",
    "- to make sure that the 1s is clear and can be recognized.\n",
    "\n",
    "**the class of others, I think we need to creat an environment sound.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/sail/sound_project/DATA/using_data_v3/clip_raw'\n",
    "\n",
    "seed = 1123\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from collections  import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "                'other':0, 'Environment':0, 'alarm': 7,\n",
    "                'en_help': 1, 'ch_help': 2, 'ja_help': 3, 'tw_help': 4, 'hk_help': 5, 'yue_help':6,\n",
    "              } \n",
    "\n",
    "clip_type = {'alarm': 'random', 'other': 'random',\n",
    "             'en_help': 'start', 'ch_help': 'start', \n",
    "             'ja_help': 'start', 'tw_help': 'start', \n",
    "             'hk_help': 'start', 'yue_help':'start',\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/sail/sound_project/DATA/using_data_v3/v3_traindata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = f'{save_path}/for_training/train'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "folder_path = f'{save_path}/for_training/test'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "folder_path = f'{save_path}/for_training/val'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "folder_path = f'{save_path}/no_padding_only_clip1s'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(wav_path, sr=sr, type='librosa'):\n",
    "    if type == 'librosa':\n",
    "        return librosa.load(wav_path, sr=sr)[0]\n",
    "    elif type == 'wavfile':\n",
    "        return wavfile.read(wav_path)[1]\n",
    "\n",
    "def clip_1s(audio, sr=sr, type='start'):\n",
    "    if type =='start':\n",
    "        return audio[:sr]\n",
    "    elif type == 'end':\n",
    "        return audio[-sr:]\n",
    "    elif type == 'random':\n",
    "        start = random.randint(0, len(audio) - sr)\n",
    "        return audio[start:start+sr]\n",
    "    else:\n",
    "        # return audio[type:type+sr]\n",
    "        raise ValueError('type must be start, end or random.')\n",
    "    \n",
    "def long_random_clip(audio, sr, count):\n",
    "    audio_list = []\n",
    "    random_time_list = [random.randint(0, len(audio)) for _ in range(count)]\n",
    "    random_time_list = list(dict.fromkeys(random_time_list))\n",
    "    for start in random_time_list:\n",
    "        audio_list.append(audio[start:start+sr])\n",
    "    return audio_list\n",
    "\n",
    "def padding_zero(audio, sr=sr, secent=1, type='a'):\n",
    "    if len(audio) < sr*secent:\n",
    "        if type=='ab':\n",
    "            total_padding = sr*secent - len(audio)\n",
    "            return np.pad(audio, (total_padding // 2, total_padding - (total_padding // 2)), 'constant', constant_values=(0, 0))\n",
    "        elif type=='a':\n",
    "            total_padding = sr*secent - len(audio)\n",
    "            return np.pad(audio, (0, total_padding), 'constant', constant_values=(0, 0))\n",
    "    else:\n",
    "        return clip_1s(audio)\n",
    "    \n",
    "def add_noise(audio, noise_factor=0.0005):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    augmented_audio = audio + noise_factor * noise\n",
    "    return augmented_audio\n",
    "\n",
    "# def slow_down_audio(audio, secent=1, rate=0.8):\n",
    "#     if len(audio) < sr*secent:\n",
    "#         return padding_zero(audio)\n",
    "#     else:\n",
    "#         return clip_1s(librosa.effects.time_stretch(audio, rate=rate))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(audio):\n",
    "    if (audio.shape[0] >= sr) & (audio.shape[0] <= sr*2):\n",
    "        audio_1 = clip_1s(audio, sr=sr, type='start')\n",
    "        audio_2 = clip_1s(audio, sr=sr, type='end')\n",
    "        audio_list = [audio_1, audio_2]\n",
    "    elif (audio.shape[0] > sr*2):\n",
    "        audio_list = long_random_clip(audio, sr,  int(audio.shape[0]/1.5//sr)+1)\n",
    "    else:\n",
    "        audio_list = [audio]\n",
    "    return audio_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2721 2721\n"
     ]
    }
   ],
   "source": [
    "X, y = [],[]\n",
    "\n",
    "def process_subfolder(subfolder_path, label):\n",
    "    for wav_file in os.listdir(subfolder_path):\n",
    "        if wav_file == 'xx':\n",
    "            continue\n",
    "        wav_file_path = os.path.join(subfolder_path, wav_file)\n",
    "        if wav_file.endswith(('.wav', '.mp3')):\n",
    "            audio = load_data(wav_file_path, sr, type='librosa')\n",
    "            X.extend(preprocess_audio(audio))\n",
    "            y.extend([label]*len(preprocess_audio(audio)))              \n",
    "        else:\n",
    "            process_subfolder(wav_file_path, label)\n",
    "            \n",
    "for file in ['other', 'alarm', 'help_data']:  # os.listdir(DATA_PATH)\n",
    "    folder_path = os.path.join(DATA_PATH, file)\n",
    "    \n",
    "    for wav_file_0 in os.listdir(folder_path):\n",
    "        if wav_file_0 == 'xx':\n",
    "            continue\n",
    "        wav_file_0_path = os.path.join(folder_path, wav_file_0)\n",
    "        \n",
    "        if file == 'other':\n",
    "            audio = load_data(wav_file_0_path, sr, type='librosa')\n",
    "            evn_audio = long_random_clip(audio, sr, 100)\n",
    "            X.extend(evn_audio) \n",
    "            y.extend([class_dict['Environment']] * len(evn_audio))\n",
    "        elif wav_file_0.endswith(('.wav', '.mp3')):\n",
    "            audio = load_data(wav_file_0_path, sr, type='librosa')\n",
    "            X.extend(preprocess_audio(audio))\n",
    "            y.extend([class_dict[file]]*len(preprocess_audio(audio)))\n",
    "        else:\n",
    "            process_subfolder(wav_file_0_path, class_dict[wav_file_0])\n",
    "print(len(X), len(y))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1400, 2: 493, 4: 278, 7: 201, 1: 169, 3: 86, 5: 64, 6: 30})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data for processing in the feature\n",
    "\n",
    "for c,i in enumerate(y):\n",
    "    wavfile.write(f'{save_path}/no_padding_only_clip1s/{[key for key, value in class_dict.items() if value == i][0]}_{Counter(y[:c])[i]}.wav', sr, X[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, audio_path in enumerate(os.listdir(os.path.join(save_path, 'no_padding_only_clip1s'))):\n",
    "    audio = padding_zero(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'), secent=1, type='a')\n",
    "    for val_name in ['_1.wav', '_15.wav', '_6.wav', '_36.wav', '_80.wav', '_74.wav', '_60.wav', '_55.wav', '_44.wav', '_73.wav']:\n",
    "        if val_name in audio_path:\n",
    "            wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "    if ('Environment_' in audio_path):\n",
    "        TF = False\n",
    "        for _ in range(200):\n",
    "            num = random.randint(0, Counter(y)[0])\n",
    "            val_name_ = f'_{num}.wav'\n",
    "            if val_name_ in audio_path:\n",
    "                TF = True                \n",
    "        if TF:\n",
    "            wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "        else:\n",
    "            wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "\n",
    "    if ('Environment_' not in audio_path):\n",
    "        audio = padding_zero(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'), secent=1, type='a')\n",
    "        for val_name in ['_1.wav', '_15.wav', '_6.wav', '_36.wav', '_80.wav', '_74.wav', '_60.wav', '_55.wav', '_44.wav', '_73.wav']:\n",
    "            if val_name in audio_path:\n",
    "                if ('tw_' in audio_path) or ('hk_' in audio_path):\n",
    "                    wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "                    wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "                    break\n",
    "                wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "            else:\n",
    "                wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_padA.wav', sr, audio)\n",
    "\n",
    "        audio = add_noise(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'))\n",
    "        audio = padding_zero(audio, secent=1, type='a')\n",
    "        if ('ja_' in audio_path) and i % 3 == 0:\n",
    "            wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_an_padA.wav', sr, audio)\n",
    "        elif ('ja_' not in audio_path):\n",
    "            wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_an_padA.wav', sr, audio)\n",
    "\n",
    "    # elif ('alarm_' not in audio_path) and ('Environment_' not in audio_path):\n",
    "    #     audio = slow_down_audio(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'))\n",
    "    #     wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_sl_padA.wav', sr, audio)\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,audio_path in enumerate(os.listdir(os.path.join(save_path, 'no_padding_only_clip1s'))):\n",
    "    if ('alarm_' not in audio_path) and ('Environment_' not in audio_path):\n",
    "    \n",
    "        audio = padding_zero(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'), secent=1, type='a')\n",
    "        for val_name in ['_1.wav', '_15.wav', '_6.wav', '_36.wav', '_80.wav', '_74.wav', '_60.wav', '_55.wav', '_44.wav', '_73.wav']:\n",
    "            if val_name in audio_path:\n",
    "                if ('tw_' in audio_path) or ('hk_' in audio_path):\n",
    "                    wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "                    wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "                    break\n",
    "                wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "\n",
    "        audio = add_noise(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'))\n",
    "        audio = padding_zero(audio, secent=1, type='a')\n",
    "        for val_name in ['_1.wav', '_15.wav', '_6.wav', '_36.wav', '_80.wav', '_74.wav', '_60.wav', '_55.wav', '_44.wav', '_73.wav']:\n",
    "            if val_name in audio_path:\n",
    "                if ('tw_' in audio_path) or ('hk_' in audio_path):\n",
    "                    wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_an_padAB.wav', sr, audio)\n",
    "                    wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_an_padAB.wav', sr, audio)\n",
    "                    break\n",
    "                # wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_an_padAB.wav', sr, audio)\n",
    "\n",
    "    if ('alarm_' not in audio_path) and ('Environment_' not in audio_path) and c%2==0:\n",
    "        continue\n",
    "        # audio = slow_down_audio(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'))\n",
    "        # wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_sl_padAB.wav', sr, audio)\n",
    "\n",
    "    else:\n",
    "        if ('Environment_' not in audio_path):\n",
    "            audio = padding_zero(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'), secent=1, type='a')\n",
    "            for val_name in ['_1.wav', '_15.wav', '_6.wav', '_36.wav', '_80.wav', '_74.wav', '_60.wav', '_55.wav', '_44.wav', '_73.wav']:\n",
    "                if val_name in audio_path:\n",
    "                    if ('tw_' in audio_path) or ('hk_' in audio_path):\n",
    "                        wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "                        wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "                        break\n",
    "                    wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "                else:\n",
    "                    wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "\n",
    "            audio = add_noise(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'))\n",
    "            audio = padding_zero(audio, secent=1, type='a')\n",
    "            for val_name in ['_1.wav', '_15.wav', '_6.wav', '_36.wav', '_80.wav', '_74.wav', '_60.wav', '_55.wav', '_44.wav', '_73.wav']:\n",
    "                if val_name in audio_path:\n",
    "                    if ('tw_' in audio_path) or ('hk_' in audio_path):\n",
    "                        wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_an_padAB.wav', sr, audio)\n",
    "                        # wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_padAB.wav', sr, audio)\n",
    "                        break\n",
    "                    # wavfile.write(f'{save_path}/for_training/val/{audio_path[:-4]}_an_padAB.wav', sr, audio)\n",
    "                else:\n",
    "                    wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_an_padAB.wav', sr, audio)\n",
    "            # if ('alarm_' not in audio_path)and (c%2==0):\n",
    "            #     audio = slow_down_audio(load_data(os.path.join(save_path, 'no_padding_only_clip1s', audio_path), sr, type='librosa'))\n",
    "            #     wavfile.write(f'{save_path}/for_training/train/{audio_path[:-4]}_sl_padAB.wav', sr, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_path = '/home/sail/sound_project/DATA/using_data_v3/clip_raw/TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wav_file in os.listdir(TEST_path):\n",
    "    for i, aud_name in enumerate(os.listdir(os.path.join(TEST_path, wav_file))):\n",
    "        audio = padding_zero(clip_1s(load_data(os.path.join(TEST_path, wav_file,aud_name))), secent=1, type='ab')\n",
    "        wavfile.write(f'{save_path}/for_training/val/{wav_file}_TEST_{i}.wav', sr, audio)\n",
    "        wavfile.write(f'{save_path}/for_training/test/{wav_file}_TEST_{i}.wav', sr, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "train\n",
      "test\n",
      "8307 8307 211 211 54 54\n"
     ]
    }
   ],
   "source": [
    "# save npz\n",
    "\n",
    "sounds_train, sounds_test, sounds_val = [], [], []\n",
    "labels_train, labels_test, labels_val = [], [], []\n",
    "\n",
    "for file in os.listdir(os.path.join(save_path, 'for_training')):\n",
    "    print(file)\n",
    "    for wav_path in os.listdir(os.path.join(save_path, 'for_training',file)):\n",
    "        path = os.path.join(save_path, 'for_training',file, wav_path)\n",
    "        wav = load_data(path, sr, type='librosa')\n",
    "        if file == 'train':\n",
    "            sounds_train.append(wav)\n",
    "            try:\n",
    "                labels_train.append(class_dict[wav_path.split('_')[0]])\n",
    "            except Exception as e:\n",
    "                labels_train.append(class_dict[wav_path.split('_')[0]+'_'+wav_path.split('_')[1]])            \n",
    "\n",
    "        elif file == 'val':\n",
    "            sounds_val.append(wav)\n",
    "            try:\n",
    "                labels_val.append(class_dict[wav_path.split('_')[0]])\n",
    "            except Exception as e:\n",
    "                labels_val.append(class_dict[wav_path.split('_')[0]+'_'+wav_path.split('_')[1]])\n",
    "\n",
    "        elif file == 'test':\n",
    "            sounds_test.append(wav)\n",
    "            try:\n",
    "                labels_test.append(class_dict[wav_path.split('_')[0]])\n",
    "            except Exception as e:\n",
    "                labels_test.append(class_dict[wav_path.split('_')[0]+'_'+wav_path.split('_')[1]])            \n",
    "\n",
    "\n",
    "print(len(sounds_train), len(labels_train), len(sounds_val), len(labels_val), len(sounds_test), len(labels_test))\n",
    "\n",
    "np.savez(r'/home/sail/sound_project/DATA/using_data_v3/data_v3.npz', sounds_train=sounds_train, labels_train=labels_train, sounds_val=sounds_val, \n",
    "         labels_val=labels_val, sounds_test=sounds_test, labels_test=labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/sail/sound_project/DATA/using_data_v3/data_v3.npz', allow_pickle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 40, 5: 31, 2: 30, 3: 30, 1: 30, 7: 24, 0: 20, 6: 6})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4142, 2: 1520, 4: 828, 7: 804, 1: 512, 5: 214, 3: 203, 6: 84})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 10, 4: 10, 1: 10, 5: 10, 3: 10, 7: 4})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4524899, -1.4327664)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.concatenate(sounds_train)), min(np.concatenate(sounds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8290101, -2.0462713)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.concatenate(sounds_train)), min(np.concatenate(sounds_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np.concatenate(X),rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio0 = load_data('/home/sail/sound_project/DATA/v2.2_traindata/for_training/train/tw_help_11_padA.wav', sr, type='librosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio0,rate=sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_dict)\n",
    "Counter(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
